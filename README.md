# Lab 2 â€” Production-Grade RAG Infrastructure

This repository is **Lab 2** in a two-part sequence.

- Lab 1: Secure single-node Weaviate fundamentals  
- Lab 2 (this repository): Build a multi-service Retrieval-Augmented Generation (RAG) chatbot using Weaviate, Ollama, FastAPI, NGINX, and Gradio.

You will not just run a chatbot, you will understand how it is built, secured, and operated.

---

# What You Will Build

By the end of this lab, you will have:

- A private vector database (Weaviate)
- A validated ingestion API
- A local LLM (Ollama) generating grounded answers
- An authentication gateway (NGINX)
- A browser-based chat UI
- A cybersecurity-focused dataset powering retrieval

The system is intentionally layered and secured to resemble real-world deployments.

# Important

The README only helps you start the system.

To understand:

- Why Weaviate is internal-only  
- Why NGINX enforces an API key  
- How retrieval works  
- How the prompt is constructed  
- How Ollama is called  
- How the services communicate  

Go to:


[Lesson Overview](https://github.com/JacksonHolmes01/Training-Module-Production-Grade-RAG-Infrastructure-Weaviate/blob/8b254c0bdf8ef20482d0a78049cd6b22d8f6549f/lessons/00-lesson-index.md)


Work through the lessons in order.

# If you are advanced and have an understanding of Weaviate and RAG Systems

Go to:

[Advanced ReadME](https://github.com/JacksonHolmes01/Training-Module-Production-Grade-RAG-Infrastructure-Weaviate/blob/8b254c0bdf8ef20482d0a78049cd6b22d8f6549f/Advanced-ReadME.md)


