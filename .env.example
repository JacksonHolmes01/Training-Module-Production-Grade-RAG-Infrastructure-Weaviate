# ==============================
# Lab 2 â€” Environment Variables
# ==============================

# ----------------------------------
# EDGE AUTHENTICATION (REQUIRED)
# ----------------------------------
# This API key is checked by NGINX before requests reach the API.
# Replace the value below with a long, random string.
# Generate one using:
#   openssl rand -hex 32
#
# Example:
# EDGE_API_KEY=a3f92d1e8b7c6f4d9a2e1c3b5f6a7d8c9e0f1a2b3c4d5e6f7a8b9c0d1e2f3a4

EDGE_API_KEY=replace-with-long-random-value


# ----------------------------------
# OLLAMA MODEL CONFIGURATION
# ----------------------------------
# This is the local LLM model Ollama will use.
# Smaller models use less RAM but may be less capable.
#
# Good default:
# llama3.1:8b
#
# If students have limited RAM, consider:
# llama3.1:latest
# phi3:mini

OLLAMA_MODEL=llama3.2:1b
OLLAMA_BASE_URL=http://ollama:11434


# ----------------------------------
# WEAVIATE CONNECTION SETTINGS
# ----------------------------------
# These are internal Docker network settings.
# You usually do NOT need to change these.

WEAVIATE_SCHEME=http
WEAVIATE_HOST=weaviate
WEAVIATE_PORT=8080


# ----------------------------------
# OPTIONAL RAG TUNING SETTINGS
# ----------------------------------
# Number of documents retrieved before generation.
# Increasing this may improve context but increases token usage.

RAG_TOP_K=5

# Maximum characters per retrieved document included in the prompt.
# Helps control prompt size.

RAG_MAX_SOURCE_CHARS=1200
